{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand Written Digit Classifier from digits 0-9 Official",
      "provenance": [],
      "authorship_tag": "ABX9TyOhG5nwuGPp6kpwX/Qmysfm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewgUaFqhfw_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "6608d27e-b802-4f9c-dd1c-a844d4ad3f08"
      },
      "source": [
        "# this project is designed to build a classifier that is able to classify digits images from the MNIST data set of the digits 0-9 \n",
        "#install packages, pip is the command to download and install all the software packages\n",
        "\n",
        "!pip install tensorflow keras numpy mnist matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /tensorflow-1.15.0/python3.6 (1.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.1)\n",
            "Collecting mnist\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.0/python3.6 (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.24.3)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.0/python3.6 (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (45.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.2.1)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BiOiTCf7s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing the necessary packages, mnist is where all the data comes from, matplotlib is intended to graph the images of digits\n",
        "# The Sequential command is used to create the entire structure of the Neural Network\n",
        "# The Dense command indicates the number of layers within the Neural Network\n",
        "# To_categorical is used to transform the data into some form of fixed values\n",
        "\n",
        "import numpy as np \n",
        "import mnist \n",
        "from keras.models import Sequential \n",
        "from keras. layers import Dense \n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMcNrET_gElB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading data set\n",
        "#The variable train_images provides the training data images\n",
        "#The variblae train_labels provides labels for the training data images\n",
        "#To evaluate the training variables, a test variable needs to be introduced,Hence, the variables test_images and test_labels\n",
        "train_images=mnist.train_images() \n",
        "train_labels=mnist.train_labels()\n",
        "test_images=mnist.test_images()\n",
        "test_labels=mnist.test_labels()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uh_ptYwgoWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ccc93147-5f11-4c07-b8b5-af9118c8d212"
      },
      "source": [
        "#Normalizing the number of pixel values(which refers to the colour of each pixel) from {0,255} to {0,1}\n",
        "#Normalizing the pixel values enables an easier way to train the neural network\n",
        "#To enable normalization, divide any pixel value that ranges from {0-255} \n",
        "#so that it enters the range of {0-1} , i.e. min value: 0/255 = 0  max value: 255/255=1\n",
        "train_images = (train_images / 255)\n",
        "test_images = (test_images/ 255)\n",
        "\n",
        "#Flattening the images allows the images to be compressed into one dimension/vector. This ensures that the image is able to go through the neural network\n",
        "#The mnist data images have dimensions of 28x28 pixeled image into a 1x784 \"vector\" \n",
        "#The reshape function enables the flattening process\n",
        "train_images = train_images.reshape((-1, 784))\n",
        "test_images = test_images.reshape((-1,784))\n",
        "\n",
        "#Print the flattened images\n",
        "#The output should be 60K rows and 784 columns of training data\n",
        "#The output should be 10K rows and 784 columns of testing data\n",
        "#Output of the shape \n",
        "print(train_images.shape) \n",
        "print(test_images.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dbe5c7f2f5a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Flattening the images allows the images to be compressed into one dimension/vector. This ensures that the image is able to go through the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#The mnist data images have dimensions of 28x28 pixeled image into a 1x784 \"vector\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwQvpT15hgbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Construct the model\n",
        "#Network consists of 3 layers, 2 layers that consist of 64 neurons using Relu function\n",
        "# 1 layer that consists of 10 neurons(digits 0-9) using Softmax function\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=784))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg-MyN2Lhsi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compiling the model involves two concpets: The loss function is used to measure how well the model does in the training stage and \n",
        "# the optimizer modifies the neural network according to the performance so that it can improve. Such changes can include \"weight sizes, learning rate\"\n",
        "#adam is one of the most well known optimizers that are used in neural networks\n",
        "#cateogrical crossentropy is a lost function that is used in neural netowrks so that it can minimize the difference between the predicted values(hypothesis)\n",
        "# and the traininge example values\n",
        "#In other words, cateogrical crossentropy is used for multi-class classification in which each data set/training example belongs to one specific class. \n",
        "#I.e, red calculator is classified as a red calcualtor , ruler is classified as a ruler (many different classes but each training example belongs to one class)\n",
        "#metrics is a parameter that is used to measure the accuracy of the training process\n",
        "model.compile(\n",
        "  optimizer= 'adam',\n",
        "    loss = 'categorical_crossentropy', #loss function for classes > 2\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzZXRBM4iCoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1d409346-672a-4604-874a-e924520f7da3"
      },
      "source": [
        "#Training the model\n",
        "#epoch is referred to number of times the vectors have gone through the network once and thus have updated the weights\n",
        "#batch size refers to the number of training examples used in one iteration\n",
        "#Interesting to note that in this case, the number of epochs resulted in a greater accuracy, but in general, it depends upon your size of data set and batch size\n",
        "model.fit(\n",
        "    train_images, \n",
        "    to_categorical(train_labels),\n",
        "    epochs=5, \n",
        "    batch_size = 3 \n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bb4691c001ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DqyFAgpiUu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8f439ac5-ba45-4544-db99-4226e21e72a9"
      },
      "source": [
        "#Evaluating the model\n",
        "model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fadf2f4f3ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.evaluate(\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEKNGXOAif-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}